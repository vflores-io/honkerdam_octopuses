{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['repo', 'parent_repo', 'child_repo', 'issue_id', 'issue_number',\n",
       "       'issue', 'text_size', 'usernames', 'users', 'mock_number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the clean (intermediate) data\n",
    "pr_df = pd.read_parquet(\"data/intermediate_data/pr_df.parquet\", engine=\"pyarrow\")\n",
    "pr_df = pr_df.head(10000)\n",
    "# check the column names\n",
    "pr_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         Title: WIP - v3\\nusername_0: \\n\n",
       "1       Title: [AppBar] Fix swipe to go back gesture f...\n",
       "2       Title: Add initial support for iOS, tvOS and w...\n",
       "3       Title: added fix for nav priority links render...\n",
       "4       Title: coqPackages.CoLoR: 1.4.0 -> 1.6.0\\nuser...\n",
       "                              ...                        \n",
       "9995    Title: server/zclient: Retry zebra message ver...\n",
       "9996    Title: Add Reason icon\\nusername_0: **Changes ...\n",
       "9997    Title: Avoid auto-hyphenation of code in the d...\n",
       "9998    Title: spark: activate R backend\\nusername_0: ...\n",
       "9999    Title: SliverChildDelegate should know which c...\n",
       "Name: issue, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's have a look at the `issues` column\n",
    "pr_df[\"issue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# let's check if there are null values in this column\n",
    "print(pr_df[\"issue\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      Title: WIP - v3\\nusername_0: \\n\n",
      "1    Title: [AppBar] Fix swipe to go back gesture f...\n",
      "2    Title: Add initial support for iOS, tvOS and w...\n",
      "3    Title: added fix for nav priority links render...\n",
      "4    Title: coqPackages.CoLoR: 1.4.0 -> 1.6.0\\nuser...\n",
      "Name: issue, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# let's preprocess the text and lowercase everything and remove the \"title\" prefix\n",
    "print(pr_df['issue'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the issue title (leave the username_0 comment out for now)\n",
    "pr_df['issue_title'] = pr_df['issue'].str.split(\"username_0: \").str[0].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while we're are it, extract the user comments too\n",
    "pr_df['issue_comments'] = pr_df['issue'].str.split(\"username_0: \").str[1].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's remove special characters and markdown, whitespace\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove markdown\n",
    "    text = re.sub(r'[#!\\[\\]<>\\-*_|]+', '', text)\n",
    "    # remove whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "pr_df['issue_title_clean'] = pr_df['issue_title'].apply(clean_text)\n",
    "pr_df['issue_comments_clean'] = pr_df['issue_comments'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                        Title: WIP v3\n",
      "1    Title: AppBar Fix swipe to go back gesture for...\n",
      "2    Title: Add initial support for iOS, tvOS and w...\n",
      "3    Title: added fix for nav priority links render...\n",
      "4                Title: coqPackages.CoLoR: 1.4.0 1.6.0\n",
      "Name: issue_title_clean, dtype: object\n",
      "                                          repo          parent_repo  \\\n",
      "0                       kaisermann/svelte-i18n           kaisermann   \n",
      "1  material-components/material-components-ios  material-components   \n",
      "2                                 dlang/phobos                dlang   \n",
      "3               patternfly/patternfly-elements           patternfly   \n",
      "4                                NixOS/nixpkgs                NixOS   \n",
      "\n",
      "                child_repo   issue_id  issue_number  \\\n",
      "0              svelte-i18n  550510104            40   \n",
      "1  material-components-ios  551064006          9444   \n",
      "2                   phobos  551980198          7355   \n",
      "3      patternfly-elements  552466427           686   \n",
      "4                  nixpkgs  553379763         78253   \n",
      "\n",
      "                                               issue  text_size  \\\n",
      "0                    Title: WIP - v3\\nusername_0: \\n       2398   \n",
      "1  Title: [AppBar] Fix swipe to go back gesture f...        355   \n",
      "2  Title: Add initial support for iOS, tvOS and w...       4306   \n",
      "3  Title: added fix for nav priority links render...       1995   \n",
      "4  Title: coqPackages.CoLoR: 1.4.0 -> 1.6.0\\nuser...       2544   \n",
      "\n",
      "                                           usernames            users  \\\n",
      "0                            [kaisermann,  elbourki]         elbourki   \n",
      "1                           [jverkoey,  bryanoltman]      bryanoltman   \n",
      "2  [wilzbach,  etcimon,  Geod24,  CyberShadow,  t...   jacob-carlborg   \n",
      "3                         [starryeyez024,  LyndseyR]         LyndseyR   \n",
      "4                                      [vbgl,  jpas]             jpas   \n",
      "\n",
      "   mock_number                                        issue_title  \\\n",
      "0        52812                                    Title: WIP - v3   \n",
      "1        38978  Title: [AppBar] Fix swipe to go back gesture f...   \n",
      "2        66742  Title: Add initial support for iOS, tvOS and w...   \n",
      "3        14002  Title: added fix for nav priority links render...   \n",
      "4        72876           Title: coqPackages.CoLoR: 1.4.0 -> 1.6.0   \n",
      "\n",
      "                                      issue_comments  \\\n",
      "0                                                      \n",
      "1  [AppBar] Fix swipe to go back gesture for MDCA...   \n",
      "2  I've only tested this on a 64 bit iPhone runni...   \n",
      "3  ## Fix bug which causes arrows to appear on pr...   \n",
      "4  <!-- Nixpkgs has a lot of new incoming Pull Re...   \n",
      "\n",
      "                                   issue_title_clean  \\\n",
      "0                                      Title: WIP v3   \n",
      "1  Title: AppBar Fix swipe to go back gesture for...   \n",
      "2  Title: Add initial support for iOS, tvOS and w...   \n",
      "3  Title: added fix for nav priority links render...   \n",
      "4              Title: coqPackages.CoLoR: 1.4.0 1.6.0   \n",
      "\n",
      "                                issue_comments_clean  \n",
      "0                                                     \n",
      "1  AppBar Fix swipe to go back gesture for MDCApp...  \n",
      "2  I've only tested this on a 64 bit iPhone runni...  \n",
      "3   Fix bug which causes arrows to appear on prim...  \n",
      "4   Nixpkgs has a lot of new incoming Pull Reques...  \n"
     ]
    }
   ],
   "source": [
    "print(pr_df['issue_title_clean'].head())\n",
    "print(pr_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the fun stuff\n",
    "\n",
    "### 1. Vectorize the Text\n",
    "\n",
    "We'll convert the `issue_title_cleaned` column into numerical representations using **TF-IDF** (Term Frequency-Inverse Document Frequency). This method is ideal for capturing the importance of words in a document relative to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# convert cleaned issue titles into a list\n",
    "issue_titles = pr_df['issue_title_clean'].dropna().tolist()\n",
    "\n",
    "# initialize and fit the tf-idf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')    # remove common stop words\n",
    "tfidf_matrix = vectorizer.fit_transform(issue_titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output matrix is a sparse matrix where each row represents an issue title as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (10000, 13209)\n"
     ]
    }
   ],
   "source": [
    "print(f'TF-IDF matrix shape: {tfidf_matrix.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute text similarities. We use the TF-IDF matrix to calculate pairwise cosine similarity, which measures how similar each issue title is to the others.\n",
    "\n",
    "NOTE: I tried to run this code:\n",
    "```py\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# calculate cosine similarity between issue titles\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix, dense_output=False)\n",
    "```\n",
    "\n",
    "but the jupyter kernel crashed. Probably the data set is too large. Let's try querying one single issue and compare it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity: 1.00 | title: Title: WIP v3\n",
      "similarity: 0.68 | title: Title: Feat/v3\n",
      "similarity: 0.67 | title: Title: Fixes for v3.0.4\n",
      "similarity: 0.62 | title: Title: bump to v3.8.5\n",
      "similarity: 0.57 | title: Title: WIP: See also\n",
      "similarity: 0.57 | title: Title: WIP\n",
      "similarity: 0.57 | title: Title: WIP\n",
      "similarity: 0.51 | title: Title: Slim v3\n",
      "similarity: 0.47 | title: Title: v3.6.0 with array helper\n",
      "similarity: 0.45 | title: Title: Bittrex api v3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_idx = 0 \n",
    "query_vector = tfidf_matrix[query_idx]\n",
    "\n",
    "# compute similarity of the query issue with all others\n",
    "similarity_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "# get the top N most similar issues\n",
    "top_indices = similarity_scores.argsort()[::-1][:10]\n",
    "for i in top_indices:\n",
    "    print(f\"similarity: {similarity_scores[i]:.2f} | title: {issue_titles[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that works, which means we can work in chunks. But before we try that, let's still try something else. Let's try using **FAISS** (Facebook AI Similarity Search).\n",
    "\n",
    "Note: Well that failed too. I did this:\n",
    "\n",
    "```py\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# convert the tf-idf matrix to numpy array\n",
    "dense_matrix = tfidf_matrix.toarray()\n",
    "\n",
    "# build faiss index\n",
    "dimension = dense_matrix.shape[1]             # number of features\n",
    "index = faiss.IndexFlatL2(dimension)          # build the index\n",
    "index.add(dense_matrix.astype(np.float32))    # add vectors to the index\n",
    "```\n",
    "\n",
    "So I guess I will resort to using the previous method but in chunks.\n",
    "\n",
    "We will process the rows of the TF-IDF matrix in manageable chunks and compute similarities agains the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "\n",
    "def compute_chunked_similarity(tfidf_matrix, chunk_size=1000, output_dir = \"data/intermediate_data/similarity_chunks/\"):\n",
    "    \"\"\"\n",
    "    compute cosine similarity in chunks to prevent memory overload.\n",
    "\n",
    "    parameters:\n",
    "    - tfidf_matrix: sparse matrix (tf-idf representation)\n",
    "    - chunk_size: number of rows to process in each chunk\n",
    "\n",
    "    returns:\n",
    "    - sparse similarity matrix\n",
    "    \"\"\"\n",
    "\n",
    "    num_rows = tfidf_matrix.shape[0]\n",
    "    similarity_chunks = []\n",
    "\n",
    "    for start_idx in range(0, num_rows, chunk_size):\n",
    "        end_idx = min(start_idx + chunk_size, num_rows)\n",
    "        print(f'processing rows {start_idx} to {end_idx}... ')\n",
    "\n",
    "        # compute similarity for the current chunk\n",
    "        chunk = tfidf_matrix[start_idx:end_idx]\n",
    "        chunk_similarity = cosine_similarity(chunk, tfidf_matrix, dense_output = False)\n",
    "\n",
    "        assert chunk_similarity.shape[1] == tfidf_matrix.shape[0], \"Chunk similarity shape does not match tfidf matrix shape\"\n",
    "\n",
    "        # save the sparse similarity matrix to disk to avoid RAM overload\n",
    "        output_path = os.path.join(output_dir, f'similarity_chunk_{start_idx}_{end_idx}.npz')\n",
    "        sp.save_npz(output_path, chunk_similarity)\n",
    "\n",
    "    print(\"all chunks processed and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rows 0 to 1000... \n",
      "processing rows 1000 to 2000... \n",
      "processing rows 2000 to 3000... \n",
      "processing rows 3000 to 4000... \n",
      "processing rows 4000 to 5000... \n",
      "processing rows 5000 to 6000... \n",
      "processing rows 6000 to 7000... \n",
      "processing rows 7000 to 8000... \n",
      "processing rows 8000 to 9000... \n",
      "processing rows 9000 to 10000... \n",
      "all chunks processed and saved\n"
     ]
    }
   ],
   "source": [
    "# run the cosine similarity in chunks\n",
    "similarity_matrix = compute_chunked_similarity(tfidf_matrix, chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honkerdam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
